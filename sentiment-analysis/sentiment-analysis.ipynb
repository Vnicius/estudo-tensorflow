{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de sentimento\n",
    "    \n",
    "O objetivo do algoritmo é identificar um sentimento positivo ou negativo\n",
    "data uma frase qualquer.\n",
    "\n",
    "## Base de Dados\n",
    "\n",
    "A base de dados é composta de dois arquivos, um contendo **frases positivas\"\" e\n",
    "outro contendo **frases negativa**. \n",
    "\n",
    "## Ideia\n",
    "\n",
    "Não se pode trabalhar diretamente com texto no tensorflow, é necessário que\n",
    "o texto seja convertido para alguma sequência numérica em vez de sequência de\n",
    "caracteres.\n",
    "\n",
    "Será contruído um dicionário léxico, as principais pelavras da bases de dados\n",
    "serão selecionadas e utilizadas para converter as frases em sequências numéricas.\n",
    "Por exemplo:\n",
    "\n",
    "**dicionário léxico** -> [gato, rato, cavalo, pulo]\n",
    "**frase** -> \"O *gato* comeu o *rato*\"\n",
    "**sequência numérica** -> [1,1,0,0] \n",
    "\n",
    "*Ver o arquivo [preprocessing.py](preprocessing.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from preprocessing import create_features_sets_and_labels\n",
    "\n",
    "train_x, train_y, test_x, test_y = create_features_sets_and_labels('database/pos.txt', 'database/neg.txt')\n",
    "\n",
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 100\n",
    "\n",
    "# height x width\n",
    "x = tf.placeholder('float', [None, len(train_x[0])])\n",
    "y = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Modelo da Rede Neural\n",
    "\n",
    "O modelo da rede neural é o mesmo do exemplo [Simple Neural Network](../simpleNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 of  10 \n",
      "loss:  7465.40562439\n",
      "Epoch  1 of  10 \n",
      "loss:  4202.7984314\n",
      "Epoch  2 of  10 \n",
      "loss:  3017.62897873\n",
      "Epoch  3 of  10 \n",
      "loss:  2352.28777885\n",
      "Epoch  4 of  10 \n",
      "loss:  1873.87875557\n",
      "Epoch  5 of  10 \n",
      "loss:  1541.15427208\n",
      "Epoch  6 of  10 \n",
      "loss:  1268.6016674\n",
      "Epoch  7 of  10 \n",
      "loss:  1032.19843578\n",
      "Epoch  8 of  10 \n",
      "loss:  897.108868599\n",
      "Epoch  9 of  10 \n",
      "loss:  736.724832535\n",
      "Accuracy:  0.555\n"
     ]
    }
   ],
   "source": [
    "def neural_network_model(data):\n",
    "    hl1 = {'weights': tf.Variable(tf.random_normal([len(train_x[0]), n_nodes_hl1])),\n",
    "           'biases': tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    \n",
    "    hl2 = {'weights': tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "           'biases': tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    \n",
    "    hl3 = {'weights': tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "           'biases': tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    \n",
    "    output_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases': tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    #(input_data * weights) + biases\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data, hl1['weights']), hl1['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1, hl2['weights']), hl2['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2, hl3['weights']), hl3['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    \n",
    "    output = tf.add(tf.matmul(l2, output_layer['weights']), output_layer['biases'])\n",
    "\n",
    "    return output\n",
    "\n",
    "def train_nn(x, y):\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    n_epochs = 10\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        #train\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            i = 0\n",
    "\n",
    "            while i < len(train_x):\n",
    "                start = i\n",
    "                end = i + batch_size\n",
    "\n",
    "                epoch_x = np.array(train_x[start:end])\n",
    "                epoch_y = np.array(train_y[start:end])\n",
    "\n",
    "                _, c = sess.run([optimizer, cost],\n",
    "                                feed_dict = {x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "\n",
    "                i += batch_size\n",
    "\n",
    "            print('Epoch ', epoch, 'of ', n_epochs, '\\nloss: ', epoch_loss)\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy: ', accuracy.eval({x: test_x,\n",
    "                                           y: test_y}))\n",
    "\n",
    "train_nn(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeos\n",
    "\n",
    "- [Vídeo 1](https://www.youtube.com/watch?v=7fcWfUavO7E&index=48&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)\n",
    "- [Vídeo 2](https://www.youtube.com/watch?v=YFxVHD2TNII&index=49&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)\n",
    "- [Vídeo 3](https://www.youtube.com/watch?v=6rDWwL6irG0&index=50&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
