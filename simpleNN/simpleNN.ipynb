{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Deep Network\n",
    "\n",
    "## Uso do MNIST Dataset\n",
    "\n",
    "Recolher dados e tratá-los é um trabalho longo e tedioso. Os dados do MNIST Dataset já estão tratados e formatados, o que nos permite focar mais na modelagem e treinamento da rede neural.\n",
    "\n",
    "Essa base de dados é composta por 60 mil exemplos de treinamento de dígitos (0-9) manuscritos e 10 mil exemplos de teste. As imagens possuem 28x28 pixels, um total de **784 pixels**. As imagens já estão tratadas com um filtro de *threshold*.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "A ideia é pegar essas imagens, passar pela rede neural e dizer qual o dígito da imagem.\n",
    "\n",
    "Cada pixel possui dois valores, 0 ou 1.\n",
    "\n",
    "## Esquema da Rede Neural\n",
    "\n",
    "- **input** > weights > hidden layer 1 (função de ativação) > weights > hidden layer 2 (função de ativação) > weights > **output layer** (\n",
    "É um Feed-forwars NN, o dado é sempre passado para frente.)\n",
    "\n",
    "- Comparação da **saída** com a **saída esperada** por meio da função de custo (Cross Entropy)\n",
    "\n",
    "- Função de otimização (AdamOptimizer) -> minimizar o custo\n",
    "\n",
    "- Backpropagation para modificar as weights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot\n",
    "\n",
    "O termo vem da eletrônica e significa que quando um componente está *hot* isso significa que ele representa algo.\n",
    "\n",
    "No caso do MNIST Dataset, como estamos trabalhondo com 10 classes de dados, ou seja, os números de 0 a 9, teremos algo como:\n",
    "\n",
    "0 = [1,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "1 = [0,1,0,0,0,0,0,0,0,0]\n",
    "\n",
    "2 = [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 500\n",
    "n_nodes_hl3 = 500\n",
    "\n",
    "n_classes = 10\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes\n",
    "\n",
    "As constantes **n_nodes** representam a quantidade de nós em cada camada, não necessariamene precisam ser do mesmo tamanho.\n",
    "\n",
    "**n_classes** representa a quantidade de classes de saída possíveis, no caso, algum dos dígitos entre 0 e 9.\n",
    "\n",
    "**batch_size** representa a quantidade de elementos do conjunto de dados de treinamento que serão utilizados em cada época, no caso serão 100 imagens por época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height x width\n",
    "x = tf.placeholder('float', [None, 784])\n",
    "y = tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders\n",
    "\n",
    "Os *placeholders* são variáveis que precisarão ter valores atribuídos quando o modelo da rede neural for executada.\n",
    "\n",
    "**x** representa os dados de entrada, tem seu valor fixado em uma de **None**, valor indeterminada, por 784, que é a quantidade de pixels de cada imagem.\n",
    "\n",
    "**y** representa os dados de saída.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    hl1 = {'weights': tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
    "           'biases': tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    \n",
    "    hl2 = {'weights': tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "           'biases': tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    \n",
    "    hl3 = {'weights': tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "           'biases': tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    \n",
    "    output_layer = {'weights': tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases': tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    #(input_data * weights) + biases\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(data, hl1['weights']), hl1['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    \n",
    "    l2 = tf.add(tf.matmul(l1, hl2['weights']), hl2['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    l3 = tf.add(tf.matmul(l2, hl3['weights']), hl3['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    \n",
    "    output = tf.add(tf.matmul(l2, output_layer['weights']), output_layer['biases'])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "As *weigths* e *biases* das camadas são variáveis com valores aleatórios e de dimensões *dado_de_entrada X dado_de_saida*, logo, as camadas internas possuem dimensões *n_nos_camada_anterior X n_nos_camada_atual*.\n",
    "\n",
    "Utilizando os métodos otimizados de equações aritiméticas do TensorFlow, são aplicadas as equações de *(input_data * weights) + biases* para cada camada, o resultado é utilziado na função de ativação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(x, y):\n",
    "    prediction = neural_network_model(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    n_epochs = 10\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        #train\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                _, c = sess.run([optimizer, cost],\n",
    "                                feed_dict = {x: epoch_x, y: epoch_y})\n",
    "                epoch_loss += c\n",
    "            print('Epoch ', epoch, 'of ', n_epochs, '\\nloss: ', epoch_loss)\n",
    "        \n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy: ', accuracy.eval({x: mnist.test.images,\n",
    "                                           y: mnist.test.labels}))\n",
    "\n",
    "train_nn(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "As variáveis de **predição**, **custo** e **otimização** são setadas com métodos do TensorFlow.\n",
    "\n",
    "Foram definidas 10 épocas de treinamento, os dados são retirados do MNIST Dataset e atribuídos às duas variáveis que terão seus valores atribuídos aos placeholders. A sessão é executada com as funções de otimização, custo e os dados.\n",
    "\n",
    "A precisão é avaliada utilziando o algoritmo treinado com um conjunto de imagens de teste e comparadas com os resultados esperados.\n",
    "\n",
    "## Vídeos\n",
    "\n",
    "### [VÍDEO 1](https://www.youtube.com/watch?v=BhpvH5DuVu8&index=46&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)\n",
    "### [VÍDEO 2](https://www.youtube.com/watch?v=PwAGxqrXSCs&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v&index=47)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
